{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1 (20 points): \n",
    "\n",
    "This problem illustrates the classification approach by using decision trees and the Lupus\n",
    "data (download the data file “sledata” from D2L). The data consists of 300 patient records. Each record contains 12\n",
    "elements. The first 11 elements stand for different symptoms and the final element of each record indicates the\n",
    "diagnosis. Build a decision tree and answer these questions.\n",
    "\n",
    "\n",
    "1) Build the best decision tree you can and explain what makes it the best. Show what criteria you used\n",
    "including the number of cases allowed in parents and children and the depth and stopping condition.  \n",
    "2) How many nodes does the final tree have and how many of them are terminal nodes?  \n",
    "3) What are the most important three Lupus data features in building the tree? Explain your answer.  \n",
    "4) Increase the parameters that let you set the number of cases allowed in parent and child nodes.   What do you\n",
    "notice with the complexity (number of nodes) of the tree? Does it increase? Explain your answer.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2 (30 points): \n",
    "\n",
    "This problem illustrates the effect of the class imbalance of the accuracy of the decision\n",
    "trees. Download the red wine quality data from the UCI machine learning repository at:\n",
    "http://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "(for a reminder of how to get this kind of data ready for SPSS, see Assignment 1)\n",
    "\n",
    "1. Consider each quality level of wine to be a different class. Report how many classes there are and what is\n",
    "the distribution of these classes for the red wine data (how many cases of each class are there).\n",
    "\n",
    "2. Repeat Problem 1 on the red wine data.\n",
    "\n",
    "3. Now bin the class variable in such a way that data is not so imbalanced with respect to the class variable.\n",
    "Repeat Problem 1 but on the data you have processed with this smoothing.\n",
    "\n",
    "4. How does the performance of the best classification model on the original class variable compare with the\n",
    "accuracy of the best classification model on the binned classification variable?\n",
    "\n",
    "5. Do you have any other ideas on how you can improve the results further?\n",
    "Showing that your idea will actually work will be graded with five extra credit points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3 (5 points): \n",
    "\n",
    "Differentiate between the following terms:\n",
    "\n",
    "a. feature selection and feature extraction  \n",
    "b. training and testing data  \n",
    "c. parametric reduction techniques and non-parametric reduction techniques  \n",
    "d. uniform binning and non-uniform binning  \n",
    "e. covariance matrix and correlation matrix  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
